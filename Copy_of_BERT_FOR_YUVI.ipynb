{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM85j1-ZX8RZ"
      },
      "source": [
        "To begin copy this notebook to your own drive:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "### Submission Instructions:\n",
        "1. **Restart the kernel** (in the menubar, select Runtime$\\rightarrow$Restart runtime)\n",
        "2. **Download the notebook** (in the menubar, select File$\\rightarrow$Download .ipynb)\n",
        "3. **Upload the downloaded notebook (.ipynb file) to your repository**.\n",
        "\n",
        "\n",
        "Make sure you fill in any place that says `YOUR CODE HERE`, and that no tests fail.  \n",
        "\n",
        "Note: To use a GPU, do the following: Runtime$\\rightarrow$Change runtime type$\\rightarrow$ GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOtck6n09468",
        "outputId": "2e539d34-0c52-4e83-ff27-95102d5e2f59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1PFOG06NEsTL6VieKQjMk1oNzyzcUtiWn\n",
            "To: /content/glove.npy\n",
            "100%|██████████| 480M/480M [00:03<00:00, 129MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1-3SxpirQjmX-RCRyRjKdP2L7G_tNgp00\n",
            "To: /content/vocab.json\n",
            "100%|██████████| 7.69M/7.69M [00:00<00:00, 79.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import gdown\n",
        "import nltk\n",
        "gdown.download('https://drive.google.com/uc?export=download&id=1PFOG06NEsTL6VieKQjMk1oNzyzcUtiWn', 'glove.npy', quiet=False)\n",
        "gdown.download('https://drive.google.com/uc?export=download&id=1-3SxpirQjmX-RCRyRjKdP2L7G_tNgp00', 'vocab.json', quiet=False)\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbkSh2AW-tpN",
        "outputId": "0272a139-70f0-4428-ac5a-7ba5d8cb5873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.17.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (5.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial.distance import cosine\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVdHM_h4h4wj"
      },
      "outputs": [],
      "source": [
        "def get_hidden_state(bert_model, tokenizer, sentence, print_words_ids=False):\n",
        "  marked_text = \"[CLS] \" + sentence + \" [SEP]\"\n",
        "\n",
        "  encoded_input = tokenizer(marked_text, return_tensors='pt')\n",
        "\n",
        "  # Split the sentence into tokens.\n",
        "  tokenized_text = tokenizer.tokenize(marked_text)\n",
        "  # Map the token strings to their vocabulary indeces.\n",
        "  indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "  if print_words_ids:\n",
        "    # Display the words with their indeces.\n",
        "    for tup in zip(tokenized_text, indexed_tokens):\n",
        "      print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n",
        "    # Output\n",
        "  with torch.no_grad():\n",
        "    output = model(**encoded_input)\n",
        "    hidden_states = output[2]\n",
        "  return hidden_states\n",
        "\n",
        "# confirm similarity\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "def sentence_similarity(sent_sim1,sent_sim2,sent_diff):\n",
        "  # Calculate the cosine similarity between the word bank \n",
        "  # in \"bank robber\" vs \"river bank\" (different meanings).\n",
        "  diff_sentence = 1 - cosine(sent_sim1, sent_diff)\n",
        "\n",
        "  # Calculate the cosine similarity between the word bank\n",
        "  # in \"bank robber\" vs \"bank vault\" (same meaning).\n",
        "  similar_sentence = 1 - cosine(sent_sim1, sent_sim2)\n",
        "\n",
        "  print('Vector similarity for  *similar*  meanings:  %.2f' % similar_sentence)\n",
        "  print('Vector similarity for *different* meanings:  %.2f' % diff_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O7ub0lXVAAD",
        "outputId": "00f37a1f-5b1e-4815-d601-e81d481d3c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]           101\n",
            "replace       5,672\n",
            "me            2,033\n",
            "by            2,011\n",
            "any           2,151\n",
            "text          3,793\n",
            "you           2,017\n",
            "'             1,005\n",
            "d             1,040\n",
            "like          2,066\n",
            ".             1,012\n",
            "[SEP]           102\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\",output_hidden_states = True).eval()\n",
        "text = \"Replace me by any text you'd like.\"\n",
        "text2 = \"switch me with whatever text you would want.\"\n",
        "text3 = \"Replace me with him in a love text.\"\n",
        "\n",
        "# Add the special tokens.\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "encoded_input = tokenizer(marked_text, return_tensors='pt')\n",
        "\n",
        "# Split the sentence into tokens.\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "# Map the token strings to their vocabulary indeces.\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "# Display the words with their indeces.\n",
        "for tup in zip(tokenized_text, indexed_tokens):\n",
        "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n",
        "\n",
        "# Output\n",
        "with torch.no_grad():\n",
        "  output = model(**encoded_input)\n",
        "  hidden_states = output[2]\n",
        "\n",
        "# calc hidden for other 2 sentences\n",
        "hidden_states2 = get_hidden_state(model,tokenizer,text2)\n",
        "hidden_states3 = get_hidden_state(model,tokenizer,text3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "DgSepiXT4obx",
        "outputId": "16f44482-e40f-4081-886a-68b5bd30d19c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "hidden_states2 = get_hidden_state(model,tokenizer,text2)# For the 5th token in our sentence, select its feature values from layer 0.\n",
        "token_i = 5\n",
        "layer_i = 0\n",
        "batch_i = 0\n",
        "vec = hidden_states[layer_i][batch_i][token_i]\n",
        "# print(hidden_states)\n",
        "\n",
        "# Plot the values as a histogram to show their distribution.\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.hist(vec, bins=200)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbr4mxydd5C9",
        "outputId": "a9b50411-031c-4274-8f62-eb94e2d6d46d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([13, 1, 14, 768])\n",
            "torch.Size([14, 13, 768])\n",
            "0 [CLS]\n",
            "1 replace\n",
            "2 me\n",
            "3 by\n",
            "4 any\n",
            "5 text\n",
            "6 you\n",
            "7 '\n",
            "8 d\n",
            "9 like\n",
            "10 .\n",
            "11 [SEP]\n"
          ]
        }
      ],
      "source": [
        "# Concatenate the tensors for all layers. We use `stack` here to\n",
        "# create a new dimension in the tensor.\n",
        "token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "\n",
        "print(token_embeddings.size())\n",
        "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "token_embeddings = token_embeddings.permute(1,0,2)\n",
        "print(token_embeddings.size())\n",
        "\n",
        "# printing word index in sentence\n",
        "for i, token_str in enumerate(tokenized_text):\n",
        "  print (i, token_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I83f0Mh4j5si"
      },
      "outputs": [],
      "source": [
        "# `hidden_states` has shape [13 x 1 x 22 x 768]\n",
        "\n",
        "# `token_vecs` is a tensor with shape [22 x 768]\n",
        "token_vecs = hidden_states[-1][0]\n",
        "token_vecs2 = hidden_states2[-1][0]\n",
        "token_vecs3 = hidden_states3[-1][0]\n",
        "\n",
        "# Calculate the average of all 22 token vectors.\n",
        "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "sentence_embedding2 = torch.mean(token_vecs2, dim=0)\n",
        "sentence_embedding3 = torch.mean(token_vecs3, dim=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr9XPWM4hBan",
        "outputId": "80f195c3-4f48-4371-a216-598e3f97cc04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector similarity for  *similar*  meanings:  0.90\n",
            "Vector similarity for *different* meanings:  0.76\n"
          ]
        }
      ],
      "source": [
        "# confirm similarity\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Calculate the cosine similarity between the word bank \n",
        "# in \"bank robber\" vs \"river bank\" (different meanings).\n",
        "diff_sentence = 1 - cosine(sentence_embedding, sentence_embedding3)\n",
        "\n",
        "# Calculate the cosine similarity between the word bank\n",
        "# in \"bank robber\" vs \"bank vault\" (same meaning).\n",
        "similar_sentence = 1 - cosine(sentence_embedding, sentence_embedding2)\n",
        "\n",
        "print('Vector similarity for  *similar*  meanings:  %.2f' % similar_sentence)\n",
        "print('Vector similarity for *different* meanings:  %.2f' % diff_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLcmWeGr4dRb",
        "outputId": "65de8778-b08f-4675-d181-d13a1555ab58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5Q328ZvhXh0",
        "outputId": "b89c06ce-327d-499d-985e-c0f29c4daf31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(30522, 768, padding_idx=0)\n"
          ]
        }
      ],
      "source": [
        "embeddings = model.get_input_embeddings()\n",
        "print(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kw-7MFNxWR2q"
      },
      "outputs": [],
      "source": [
        "      # (10): BertLayer(\n",
        "      #   (attention): BertAttention(\n",
        "      #     (self): BertSelfAttention(\n",
        "      #       (query): Linear(in_features=768, out_features=768, bias=True)\n",
        "      #       (key): Linear(in_features=768, out_features=768, bias=True)\n",
        "      #       (value): Linear(in_features=768, out_features=768, bias=True)\n",
        "      #       (dropout): Dropout(p=0.1, inplace=False)\n",
        "      #     )\n",
        "      #     (output): BertSelfOutput(\n",
        "      #       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
        "      #       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
        "      #       (dropout): Dropout(p=0.1, inplace=False)\n",
        "      #     )\n",
        "      #   )\n",
        "      #   (intermediate): BertIntermediate(\n",
        "      #     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
        "      #   )\n",
        "      #   (output): BertOutput(\n",
        "      #     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
        "      #     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
        "      #     (dropout): Dropout(p=0.1, inplace=False)\n",
        "      #   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0y6zqr3WDnc"
      },
      "outputs": [],
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkqboCBHVfrD",
        "outputId": "877b0f58-81d4-42f7-b813-5961c1d629eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder.layer.0.attention.output.dense.weight\n",
            "encoder.layer.0.attention.output.dense.bias\n",
            "encoder.layer.0.intermediate.dense.weight\n",
            "encoder.layer.0.intermediate.dense.bias\n",
            "encoder.layer.0.output.dense.weight\n",
            "encoder.layer.0.output.dense.bias\n",
            "encoder.layer.1.attention.output.dense.weight\n",
            "encoder.layer.1.attention.output.dense.bias\n",
            "encoder.layer.1.intermediate.dense.weight\n",
            "encoder.layer.1.intermediate.dense.bias\n",
            "encoder.layer.1.output.dense.weight\n",
            "encoder.layer.1.output.dense.bias\n",
            "encoder.layer.2.attention.output.dense.weight\n",
            "encoder.layer.2.attention.output.dense.bias\n",
            "encoder.layer.2.intermediate.dense.weight\n",
            "encoder.layer.2.intermediate.dense.bias\n",
            "encoder.layer.2.output.dense.weight\n",
            "encoder.layer.2.output.dense.bias\n",
            "encoder.layer.3.attention.output.dense.weight\n",
            "encoder.layer.3.attention.output.dense.bias\n",
            "encoder.layer.3.intermediate.dense.weight\n",
            "encoder.layer.3.intermediate.dense.bias\n",
            "encoder.layer.3.output.dense.weight\n",
            "encoder.layer.3.output.dense.bias\n",
            "encoder.layer.4.attention.output.dense.weight\n",
            "encoder.layer.4.attention.output.dense.bias\n",
            "encoder.layer.4.intermediate.dense.weight\n",
            "encoder.layer.4.intermediate.dense.bias\n",
            "encoder.layer.4.output.dense.weight\n",
            "encoder.layer.4.output.dense.bias\n",
            "encoder.layer.5.attention.output.dense.weight\n",
            "encoder.layer.5.attention.output.dense.bias\n",
            "encoder.layer.5.intermediate.dense.weight\n",
            "encoder.layer.5.intermediate.dense.bias\n",
            "encoder.layer.5.output.dense.weight\n",
            "encoder.layer.5.output.dense.bias\n",
            "encoder.layer.6.attention.output.dense.weight\n",
            "encoder.layer.6.attention.output.dense.bias\n",
            "encoder.layer.6.intermediate.dense.weight\n",
            "encoder.layer.6.intermediate.dense.bias\n",
            "encoder.layer.6.output.dense.weight\n",
            "encoder.layer.6.output.dense.bias\n",
            "encoder.layer.7.attention.output.dense.weight\n",
            "encoder.layer.7.attention.output.dense.bias\n",
            "encoder.layer.7.intermediate.dense.weight\n",
            "encoder.layer.7.intermediate.dense.bias\n",
            "encoder.layer.7.output.dense.weight\n",
            "encoder.layer.7.output.dense.bias\n",
            "encoder.layer.8.attention.output.dense.weight\n",
            "encoder.layer.8.attention.output.dense.bias\n",
            "encoder.layer.8.intermediate.dense.weight\n",
            "encoder.layer.8.intermediate.dense.bias\n",
            "encoder.layer.8.output.dense.weight\n",
            "encoder.layer.8.output.dense.bias\n",
            "encoder.layer.9.attention.output.dense.weight\n",
            "encoder.layer.9.attention.output.dense.bias\n",
            "encoder.layer.9.intermediate.dense.weight\n",
            "encoder.layer.9.intermediate.dense.bias\n",
            "encoder.layer.9.output.dense.weight\n",
            "encoder.layer.9.output.dense.bias\n",
            "encoder.layer.10.attention.output.dense.weight\n",
            "encoder.layer.10.attention.output.dense.bias\n",
            "encoder.layer.10.intermediate.dense.weight\n",
            "encoder.layer.10.intermediate.dense.bias\n",
            "encoder.layer.10.output.dense.weight\n",
            "encoder.layer.10.output.dense.bias\n",
            "encoder.layer.11.attention.output.dense.weight\n",
            "encoder.layer.11.attention.output.dense.bias\n",
            "encoder.layer.11.intermediate.dense.weight\n",
            "encoder.layer.11.intermediate.dense.bias\n",
            "encoder.layer.11.output.dense.weight\n",
            "encoder.layer.11.output.dense.bias\n"
          ]
        }
      ],
      "source": [
        "# dir(model)\n",
        "\n",
        "for name,x in model.named_parameters():\n",
        "  # print()\n",
        "  if \"intermediate.dense\" in name  or \"output.dense\" in name:\n",
        "    # x = x._set(0)\n",
        "    print(name)\n",
        "\n",
        "  # break\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HvPThWvCq1F",
        "outputId": "33ddc498-5846-4d0a-b5bd-d02f46b928a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([768, 768])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
        "\n",
        "st = model.state_dict()\n",
        "a = st[\"encoder.layer.0.attention.output.dense.weight\"]\n",
        "print(a.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3U-ecJmW9Br",
        "outputId": "e38f5f4c-b390-4990-ff13-112b2ac22c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [-0., 0., 0.,  ..., 0., -0., 0.],\n",
            "        [-0., 0., -0.,  ..., -0., -0., 0.],\n",
            "        ...,\n",
            "        [-0., 0., 0.,  ..., 0., 0., -0.],\n",
            "        [0., 0., 0.,  ..., -0., 0., 0.],\n",
            "        [-0., 0., 0.,  ..., -0., -0., -0.]])\n"
          ]
        }
      ],
      "source": [
        "# How to replace the model's weights\n",
        "st = model.state_dict()\n",
        "st[\"encoder.layer.1.intermediate.dense.weight\"]  = st[\"encoder.layer.1.intermediate.dense.weight\"]*0\n",
        "model.load_state_dict(st)\n",
        "print(model.state_dict()[\"encoder.layer.1.intermediate.dense.weight\"])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbpG4pngtqr-"
      },
      "outputs": [],
      "source": [
        "emb = model.get_input_embeddings()\n",
        "X = emb.weight.cpu().detach().numpy()\n",
        "# y= st[\"encoder.layer.2.intermediate.dense.weight\"].cpu().numpy()\n",
        "y= st[\"encoder.layer.0.attention.output.dense.weight\"].cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teONyISEtsFE"
      },
      "outputs": [],
      "source": [
        "# import sklearn\n",
        "# from sklearn.linear_model import OrthogonalMatchingPursuit\n",
        "# print(X.shape)\n",
        "# print(y.shape)\n",
        "# mp = OrthogonalMatchingPursuit(normalize=False).fit(X.T, y.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HXTDLQyuaPh"
      },
      "outputs": [],
      "source": [
        "# mp.score(X.T,y.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFcL0sNOt9LF"
      },
      "outputs": [],
      "source": [
        "# j = mp.predict(X.T)\n",
        "# print(j.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How to replace the model's weights\n",
        "# print(model.state_dict()[\"encoder.layer.0.attention.output.dense.weight\"])\n",
        "# st = model.state_dict()\n",
        "# st[\"encoder.layer.0.attention.output.dense.weight\"]  = torch.Tensor(j.T)\n",
        "# model.load_state_dict(st)\n",
        "# print(model.state_dict()[\"encoder.layer.0.attention.output.dense.weight\"])"
      ],
      "metadata": {
        "id": "Kwwp1eTU4TuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calc hidden for sentences with the model - new weights \n",
        "hidden_states = get_hidden_state(model,tokenizer,text)\n",
        "hidden_states2 = get_hidden_state(model,tokenizer,text2)\n",
        "hidden_states3 = get_hidden_state(model,tokenizer,text3)\n",
        "\n",
        "\n",
        "for i in range(13):\n",
        "  print(f\"Layer {i}\")\n",
        "  # # `hidden_states` has shape [13 x 1 x 22 x 768]\n",
        "  # `token_vecs` is a tensor with shape [22 x 768]\n",
        "\n",
        "  # take the i'th layer \n",
        "  token_vecs = hidden_states[i][0]\n",
        "  token_vecs2 = hidden_states2[i][0]\n",
        "  token_vecs3 = hidden_states3[i][0]\n",
        "\n",
        "  # Calculate the average of all 22 token vectors. - a sentence represntation\n",
        "  sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "  sentence_embedding2 = torch.mean(token_vecs2, dim=0)\n",
        "  sentence_embedding3 = torch.mean(token_vecs3, dim=0)\n",
        "\n",
        "  sentence_similarity(sentence_embedding,sentence_embedding2,sentence_embedding3) # Calculate based on cosine similarity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlGAFPSj5mk7",
        "outputId": "bdc8d57a-f050-4148-9a19-22792e5ee59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 0\n",
            "Vector similarity for  *similar*  meanings:  0.87\n",
            "Vector similarity for *different* meanings:  0.90\n",
            "Layer 1\n",
            "Vector similarity for  *similar*  meanings:  0.89\n",
            "Vector similarity for *different* meanings:  0.89\n",
            "Layer 2\n",
            "Vector similarity for  *similar*  meanings:  0.93\n",
            "Vector similarity for *different* meanings:  0.93\n",
            "Layer 3\n",
            "Vector similarity for  *similar*  meanings:  0.94\n",
            "Vector similarity for *different* meanings:  0.90\n",
            "Layer 4\n",
            "Vector similarity for  *similar*  meanings:  0.93\n",
            "Vector similarity for *different* meanings:  0.88\n",
            "Layer 5\n",
            "Vector similarity for  *similar*  meanings:  0.93\n",
            "Vector similarity for *different* meanings:  0.89\n",
            "Layer 6\n",
            "Vector similarity for  *similar*  meanings:  0.93\n",
            "Vector similarity for *different* meanings:  0.90\n",
            "Layer 7\n",
            "Vector similarity for  *similar*  meanings:  0.93\n",
            "Vector similarity for *different* meanings:  0.88\n",
            "Layer 8\n",
            "Vector similarity for  *similar*  meanings:  0.92\n",
            "Vector similarity for *different* meanings:  0.84\n",
            "Layer 9\n",
            "Vector similarity for  *similar*  meanings:  0.91\n",
            "Vector similarity for *different* meanings:  0.81\n",
            "Layer 10\n",
            "Vector similarity for  *similar*  meanings:  0.91\n",
            "Vector similarity for *different* meanings:  0.80\n",
            "Layer 11\n",
            "Vector similarity for  *similar*  meanings:  0.93\n",
            "Vector similarity for *different* meanings:  0.84\n",
            "Layer 12\n",
            "Vector similarity for  *similar*  meanings:  0.91\n",
            "Vector similarity for *different* meanings:  0.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download wikitext dataset\n",
        "from datasets import list_datasets, load_dataset, list_metrics, load_metric\n",
        "\n",
        "wikitext_dataset = load_dataset('wikitext', 'wikitext-103-v1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "629647024d5b4520b47595f042b840e6",
            "b9bc1e69a18d402caa08c56a2352b1fc",
            "23345dc49545476c933816beffee947e",
            "96ef8211ab8643529b8f6cbaf424423d",
            "ffc558068aa2403da547b60f48f6dfe9",
            "2ebd5b92986e4c93ba4d3372ec920865",
            "6b5e72763a364be188807ab7d3516270",
            "05ebf934d0bf47648d7366f060cace0f",
            "ea6d73528483485bac7ca6c6ab45fd19",
            "cdec74ff42094ecc927f8954f23db81a",
            "f286cf34f7c0478e909196d1162480fc"
          ]
        },
        "id": "h9mm0NfKIh00",
        "outputId": "1c33741f-e23a-4033-81f7-2b9caa51dc81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "629647024d5b4520b47595f042b840e6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(wikitext_dataset)\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "batch_sentences = wikitext_dataset['test'][4000:5500]['text']\n",
        "# batch_sentences = [data['text'] for i,data in enumerate(wikitext_dataset['train'][1:1500]]\n",
        "model.to(device)\n",
        "output_list = [0]*1500\n",
        "with torch.no_grad():\n",
        "  for i,sent in enumerate(batch_sentences):\n",
        "    encoded_input = tokenizer(sent,return_tensors='pt').to(device)\n",
        "    output = model(**encoded_input)\n",
        "    output_list[i] = output[2]"
      ],
      "metadata": {
        "id": "ZcPzlm0sNlt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_list[i][0].size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvoUeQD9VUjW",
        "outputId": "d400943d-52fc-402c-f851-ca6a801d7716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of BERT_FOR_YUVI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "629647024d5b4520b47595f042b840e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b9bc1e69a18d402caa08c56a2352b1fc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_23345dc49545476c933816beffee947e",
              "IPY_MODEL_96ef8211ab8643529b8f6cbaf424423d",
              "IPY_MODEL_ffc558068aa2403da547b60f48f6dfe9"
            ]
          }
        },
        "b9bc1e69a18d402caa08c56a2352b1fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23345dc49545476c933816beffee947e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2ebd5b92986e4c93ba4d3372ec920865",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b5e72763a364be188807ab7d3516270"
          }
        },
        "96ef8211ab8643529b8f6cbaf424423d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_05ebf934d0bf47648d7366f060cace0f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea6d73528483485bac7ca6c6ab45fd19"
          }
        },
        "ffc558068aa2403da547b60f48f6dfe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cdec74ff42094ecc927f8954f23db81a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 78.52it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f286cf34f7c0478e909196d1162480fc"
          }
        },
        "2ebd5b92986e4c93ba4d3372ec920865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b5e72763a364be188807ab7d3516270": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05ebf934d0bf47648d7366f060cace0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea6d73528483485bac7ca6c6ab45fd19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cdec74ff42094ecc927f8954f23db81a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f286cf34f7c0478e909196d1162480fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}