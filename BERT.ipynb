{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXhsEvzIjlZP"
      },
      "source": [
        "#Fast OMP Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VM6DBfeWjtT6"
      },
      "outputs": [],
      "source": [
        "%load_ext Cython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wQlHgEOj2lW"
      },
      "outputs": [],
      "source": [
        "%%cython\n",
        "\n",
        "\"\"\"Cython allows us to call lower level c-code instead of using Python. It can be a surprisingly big speedup!\"\"\"\n",
        "import cython\n",
        "from scipy.linalg.cython_blas cimport idamax, isamax, daxpy, dgemv, dtrmv, dcopy\n",
        "from scipy.linalg.cython_lapack cimport dposv, dppsv, sppsv\n",
        "\n",
        "ctypedef fused proj_t:\n",
        "    double\n",
        "    float\n",
        "\n",
        "@cython.boundscheck(False)\n",
        "@cython.wraparound(False)\n",
        "cpdef void ppsv(proj_t[:, :] As,\n",
        "           proj_t[:, :, :] ys) nogil:\n",
        "    # Works not for strided array I think. And please do not give a negative-stride array.\n",
        "    cdef Py_ssize_t B = ys.shape[0]  # Batch size\n",
        "    cdef int N = ys.shape[1]\n",
        "    cdef int nrhs = ys.shape[2]\n",
        "    cdef int info = 0  # Just discard any error signals ;)\n",
        "    cdef char uplo = 85 # The letter 'U', since we store the lower triangle and fortran sees As.T.\n",
        "    # cdef int ldb = ys[0].strides[0] // sizeof(double)\n",
        "\n",
        "    for i from 0 <= i < B:\n",
        "        if proj_t is double:  # One C-function is created for each of these specializations! :) (see argmax_blast.__signatures__)\n",
        "            dppsv(&uplo, &N, &nrhs, &As[i, 0], &ys[i, 0, 0], &N, &info)\n",
        "        elif proj_t is float:\n",
        "            sppsv(&uplo, &N, &nrhs, &As[i, 0], &ys[i, 0, 0], &N, &info)\n",
        "\n",
        "\n",
        "@cython.boundscheck(False)\n",
        "@cython.wraparound(False)\n",
        "cpdef void argmax_blast(proj_t[:, :] projections,\n",
        "                 long long[:] output) nogil:\n",
        "    # TODO: Numpy has its own indexing data-type - this may be a more appropriate output, and may even be faster.\n",
        "    # http://conference.scipy.org/static/wiki/seljebotn_cython.pdf\n",
        "    # https://apprize.best/python/cython/3.html\n",
        "    cdef Py_ssize_t B = projections.shape[0]\n",
        "    cdef int N = projections.shape[1]\n",
        "    cdef int incx = projections.strides[1] // sizeof(proj_t)  # Stride between elements.\n",
        "    cdef Py_ssize_t i\n",
        "    for i from 0 <= i < B:\n",
        "        if proj_t is double:\n",
        "            output[i] = idamax(&N, &projections[i, 0], &incx) - 1\n",
        "        elif proj_t is float:\n",
        "            output[i] = isamax(&N, &projections[i, 0], &incx) - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYR0qH2Xj73q"
      },
      "outputs": [],
      "source": [
        "\"\"\"This cell contains the code we've implemented. You should be able to call each function directly, or alternatively, see our example calls below\"\"\"\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.utils\n",
        "import torch.utils.data\n",
        "from sklearn.datasets import make_sparse_coded_signal\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
        "from contextlib import contextmanager\n",
        "from timeit import default_timer\n",
        "# from test_omp import omp_naive\n",
        "# from test import *  # FIXME: better name\n",
        "# from line_profiler import line_profiler\n",
        "\n",
        "n_components, n_features = 100, 100\n",
        "n_nonzero_coefs = 17\n",
        "n_samples = 50\n",
        "\n",
        "@contextmanager\n",
        "def elapsed_timer():\n",
        "    # https://stackoverflow.com/questions/7370801/how-to-measure-elapsed-time-in-python\n",
        "    start = default_timer()\n",
        "    elapser = lambda: default_timer() - start\n",
        "    yield lambda: elapser()\n",
        "    end = default_timer()\n",
        "    elapser = lambda: end-start\n",
        "\n",
        "\n",
        "def run_omp(X, y, n_nonzero_coefs, precompute=True, tol=0.0, normalize=False, fit_intercept=False, alg='naive'):\n",
        "    if not isinstance(X, torch.Tensor):\n",
        "        X = torch.as_tensor(X)\n",
        "        y = torch.as_tensor(y)\n",
        "\n",
        "    # We can either return sets, (sets, solutions), or xests\n",
        "    # These are all equivalent, but are simply more and more dense representations.\n",
        "    # Given sets and X and y one can (re-)construct xests. The second is just a sparse vector repr.\n",
        "\n",
        "    # https://github.com/scikit-learn/scikit-learn/blob/15a949460dbf19e5e196b8ef48f9712b72a3b3c3/sklearn/linear_model/_omp.py#L690\n",
        "    if fit_intercept or normalize:\n",
        "        X = X.clone()\n",
        "        assert not isinstance(precompute, torch.Tensor), \"If user pre-computes XTX they can also pre-normalize X\" \\\n",
        "                                                         \" as well, so normalize and fit_intercept must be set false.\"\n",
        "\n",
        "    if fit_intercept:\n",
        "        X = X - X.mean(0)\n",
        "        y = y - y.mean(1)[:, None]\n",
        "\n",
        "    # To keep a good condition number on X, especially with Cholesky compared to LU factorization,\n",
        "    # we should probably always normalize it (OMP is invariant anyways)\n",
        "    if normalize is True:  # User can also just optionally supply pre-computed norms.\n",
        "        normalize = (X * X).sum(0).sqrt()\n",
        "        X /= normalize[None, :]\n",
        "\n",
        "    if precompute is True or alg == 'v0':\n",
        "        precompute = X.T @ X\n",
        "\n",
        "    # If n_nonzero_coefs is equal to M, one should just return lstsq\n",
        "    if alg == 'naive':\n",
        "        sets, solutions, lengths = omp_naive(X, y, n_nonzero_coefs=n_nonzero_coefs, XTX=precompute, tol=tol)\n",
        "    elif alg == 'v0':\n",
        "        sets, solutions, lengths = omp_v0(X, y, n_nonzero_coefs=n_nonzero_coefs, XTX=precompute, tol=tol)\n",
        "\n",
        "\n",
        "    solutions = solutions.squeeze(-1)\n",
        "    if normalize is not False:\n",
        "        solutions /= normalize[sets]\n",
        "\n",
        "    xests = y.new_zeros(y.shape[0], X.shape[1])\n",
        "    if lengths is None:\n",
        "        xests[torch.arange(y.shape[0], dtype=sets.dtype, device=sets.device)[:, None], sets] = solutions\n",
        "    else:\n",
        "        for i in range(y.shape[0]):\n",
        "            # xests[i].scatter_(-1, sets[i, :lengths[i]], solutions[i, :lengths[i]])\n",
        "            xests[i, sets[i, :lengths[i]]] = solutions[i, :lengths[i]]\n",
        "\n",
        "    return xests\n",
        "\n",
        "def batch_mm(matrix, matrix_batch, return_contiguous=True):\n",
        "    \"\"\"\n",
        "    :param matrix: Sparse or dense matrix, size (m, n).\n",
        "    :param matrix_batch: Batched dense matrices, size (b, n, k).\n",
        "    :return: The batched matrix-matrix product, size (m, n) x (b, n, k) = (b, m, k).\n",
        "    \"\"\"\n",
        "    # One dgemm is faster than many dgemv.\n",
        "    # From https://github.com/pytorch/pytorch/issues/14489#issuecomment-607730242\n",
        "    batch_size = matrix_batch.shape[0]\n",
        "    # Stack the vector batch into columns. (b, n, k) -> (n, b, k) -> (n, b*k)\n",
        "    vectors = matrix_batch.transpose([1, 0, 2]).reshape(matrix.shape[1], -1)\n",
        "\n",
        "    # A matrix-matrix product is a batched matrix-vector product of the columns.\n",
        "    # And then reverse the reshaping. (m, n) x (n, b*k) = (m, b*k) -> (m, b, k) -> (b, m, k)\n",
        "    if return_contiguous:\n",
        "        result = np.empty_like(matrix_batch, shape=(batch_size, matrix.shape[0], matrix_batch.shape[2]))\n",
        "        np.matmul(matrix, vectors, out=result.transpose([1, 0, 2]).reshape(matrix.shape[0], -1))\n",
        "    else:\n",
        "        result = (matrix @ vectors).reshape(matrix.shape[0], batch_size, -1).transpose([1, 0, 2])\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def innerp(x, y=None, out=None):\n",
        "    if y is None:\n",
        "        y = x\n",
        "    if out is not None:\n",
        "        out = out[:, None, None]  # Add space for two singleton dimensions.\n",
        "    return torch.matmul(x[..., None, :], y[..., :, None], out=out)[..., 0, 0]\n",
        "\n",
        "def cholesky_solve(ATA, ATy):\n",
        "    if ATA.dtype == torch.half or ATy.dtype == torch.half:\n",
        "        return ATy.to(torch.float).cholesky_solve(torch.cholesky(ATA.to(torch.float))).to(ATy.dtype)\n",
        "    return ATy.cholesky_solve(torch.cholesky(ATA)).to(ATy.dtype)\n",
        "\n",
        "\n",
        "def omp_naive(X, y, n_nonzero_coefs, tol=None, XTX=None):\n",
        "    on_cpu = not (y.is_cuda or y.dtype == torch.half)\n",
        "    # torch.cuda.synchronize()\n",
        "    # Given X as an MxN array and y as an BxN array, do omp to approximately solve Xb=y\n",
        "\n",
        "    # Base variables\n",
        "    XT = X.contiguous().t()  # Store XT in fortran-order.\n",
        "    y = y.contiguous()\n",
        "    r = y.clone()\n",
        "\n",
        "    sets = y.new_zeros((n_nonzero_coefs, y.shape[0]), dtype=torch.long).t()\n",
        "    if tol:\n",
        "        result_sets = sets.new_zeros(y.shape[0], n_nonzero_coefs)\n",
        "        result_lengths = sets.new_zeros(y.shape[0])\n",
        "        result_solutions = y.new_zeros((y.shape[0], n_nonzero_coefs, 1))\n",
        "        original_indices = torch.arange(y.shape[0], dtype=sets.dtype, device=sets.device)\n",
        "\n",
        "    # Trade b*k^2+bk+bkM = O(bkM) memory for much less compute time. (This has to be done anyways since we are batching,\n",
        "    # otherwise one could just permute columns of X in-place as in https://github.com/scikit-learn/scikit-learn/blob/15a949460dbf19e5e196b8ef48f9712b72a3b3c3/sklearn/linear_model/_omp.py#L28 )\n",
        "    ATs = y.new_zeros(r.shape[0], n_nonzero_coefs, X.shape[0])\n",
        "    ATys = y.new_zeros(r.shape[0], n_nonzero_coefs, 1)\n",
        "    ATAs = torch.eye(n_nonzero_coefs, dtype=y.dtype, device=y.device)[None].repeat(r.shape[0], 1, 1)\n",
        "    if on_cpu:\n",
        "        # For CPU it is faster to use a packed representation of the lower triangle in ATA.\n",
        "        tri_idx = torch.tril_indices(n_nonzero_coefs, n_nonzero_coefs, device=sets.device, dtype=sets.dtype)\n",
        "        ATAs = ATAs[:, tri_idx[0], tri_idx[1]]\n",
        "\n",
        "    solutions = y.new_zeros((r.shape[0], 0))\n",
        "\n",
        "    for k in range(n_nonzero_coefs+bool(tol)):\n",
        "        # STOPPING CRITERIA\n",
        "        if tol:\n",
        "            problems_done = innerp(r) <= tol\n",
        "            if k == n_nonzero_coefs:\n",
        "                problems_done[:] = True\n",
        "\n",
        "            if problems_done.any():\n",
        "                remaining = ~problems_done\n",
        "\n",
        "                orig_idxs = original_indices[problems_done]\n",
        "                result_sets[orig_idxs, :k] = sets[problems_done, :k]\n",
        "                result_solutions[orig_idxs, :k] = solutions[problems_done]\n",
        "                result_lengths[orig_idxs] = k\n",
        "                original_indices = original_indices[remaining]\n",
        "\n",
        "                # original_indices = original_indices[remaining]\n",
        "                ATs = ATs[remaining]\n",
        "                ATys = ATys[remaining]\n",
        "                ATAs = ATAs[remaining]\n",
        "                sets = sets[remaining]\n",
        "                y = y[remaining]\n",
        "                r = r[remaining]\n",
        "                if problems_done.all():\n",
        "                    return result_sets, result_solutions, result_lengths\n",
        "        # GET PROJECTIONS AND INDICES TO ADD\n",
        "        if on_cpu:\n",
        "            projections = batch_mm(XT.numpy(), r[:, :, None].numpy())\n",
        "            argmax_blast(projections.squeeze(-1), sets[:, k].numpy())\n",
        "        else:\n",
        "            projections = XT @ r[:, :, None]\n",
        "            sets[:, k] = projections.abs().sum(-1).argmax(-1)  # Sum is just a squeeze, but would be relevant in SOMP.\n",
        "\n",
        "        # UPDATE AT\n",
        "        AT = ATs[:, :k + 1, :]\n",
        "        updateA = XT[sets[:, k], :]\n",
        "        AT[:, k, :] = updateA\n",
        "\n",
        "        # UPDATE ATy based on AT\n",
        "        ATy = ATys[:, :k + 1]\n",
        "        innerp(updateA, y, out=ATy[:, k, 0])\n",
        "\n",
        "        # UPDATE ATA based on AT or precomputed XTX.\n",
        "        if on_cpu:\n",
        "            packed_idx = k * (k - 1) // 2\n",
        "            if XTX is not None:  # Update based on precomputed XTX.\n",
        "                ATAs.t()[k + packed_idx:packed_idx + 2 * k + 1, :].t().numpy()[:] = XTX[sets[:, k, None], sets[:, :k + 1]]\n",
        "            else:\n",
        "                np.matmul(AT[:, :k + 1, :].numpy(), updateA[:, :, None].numpy(),\n",
        "                          out=ATAs.t()[k + packed_idx:packed_idx + 2 * k + 1, :].t()[:, :, None].numpy())\n",
        "        else:\n",
        "            ATA = ATAs[:, :k + 1, :k + 1]\n",
        "            if XTX is not None:\n",
        "                ATA[:, k, :k + 1] = XTX[sets[:, k, None], sets[:, :k + 1]]\n",
        "            else:\n",
        "                # Update ATAs by adding the new column of inner products.\n",
        "                torch.bmm(AT[:, :k + 1, :], updateA[:, :, None], out=ATA[:, k, :k + 1, None])\n",
        "\n",
        "        # SOLVE ATAx = ATy.\n",
        "        if on_cpu:\n",
        "            solutions = ATy.permute(0, 2, 1).clone().permute(0, 2, 1)  # Get a copy.\n",
        "            ppsv(ATAs.t()[:packed_idx + 2 * k + 1, :].t().contiguous().numpy(), solutions.numpy())\n",
        "        else:\n",
        "            ATA[:, :k, k] = ATA[:, k, :k]  # Copy lower triangle to upper triangle.\n",
        "            solutions = cholesky_solve(ATA, ATy)\n",
        "\n",
        "        # FINALLY, GET NEW RESIDUAL r=y-Ax\n",
        "        if on_cpu:\n",
        "            np.subtract(y.numpy(), (AT.permute(0, 2, 1).numpy() @ solutions.numpy()).squeeze(-1), out=r.numpy())\n",
        "        else:\n",
        "            torch.baddbmm(y[:, :, None], AT.permute(0, 2, 1), solutions, beta=-1, out=r[:, :, None])\n",
        "\n",
        "    return sets, solutions, None\n",
        "\n",
        "def omp_v0(X, y, XTX, n_nonzero_coefs=None, tol=None, inverse_cholesky=True):\n",
        "    B = y.shape[0]\n",
        "    normr2 = innerp(y)  # Norm squared of residual.\n",
        "    projections = (X.transpose(1, 0) @ y[:, :, None]).squeeze(-1)\n",
        "    sets = y.new_zeros(n_nonzero_coefs, B, dtype=torch.int64)\n",
        "\n",
        "    if inverse_cholesky:\n",
        "        # Doing the inverse-cholesky iteratively uses more memory,\n",
        "        # but takes less time than waiting till solving the problem in the end it seems.\n",
        "        # (Since F is triangular it could be __even faster__ to multiply, prob. not on GPU tho.)\n",
        "        F = torch.eye(n_nonzero_coefs, dtype=y.dtype, device=y.device).repeat(B, 1, 1)\n",
        "        a_F = y.new_zeros(n_nonzero_coefs, B, 1)\n",
        "\n",
        "    D_mybest = y.new_empty(B, n_nonzero_coefs, XTX.shape[0])\n",
        "    temp_F_k_k = y.new_ones((B, 1))\n",
        "\n",
        "    if tol:\n",
        "        result_lengths = sets.new_zeros(y.shape[0])\n",
        "        result_solutions = y.new_zeros((y.shape[0], n_nonzero_coefs, 1))\n",
        "        finished_problems = sets.new_zeros(y.shape[0], dtype=torch.bool)\n",
        "\n",
        "    for k in range(n_nonzero_coefs+bool(tol)):\n",
        "        # STOPPING CRITERIA\n",
        "        if tol:\n",
        "            problems_done = normr2 <= tol\n",
        "            if k == n_nonzero_coefs:\n",
        "                problems_done[:] = True\n",
        "\n",
        "            if problems_done.any():\n",
        "                new_problems_done = problems_done & ~finished_problems\n",
        "                finished_problems.logical_or_(problems_done)\n",
        "                result_lengths[new_problems_done] = k\n",
        "                if inverse_cholesky:\n",
        "                    result_solutions[new_problems_done, :k] = F[new_problems_done, :k, :k].permute(0, 2, 1) @ a_F[:k, new_problems_done].permute(1, 0, 2)\n",
        "                else:\n",
        "                    assert False, \"inverse_cholesky=False with tol != None is not handled yet\"\n",
        "                if problems_done.all():\n",
        "                    return sets.t(), result_solutions, result_lengths\n",
        "\n",
        "        sets[k] = projections.abs().argmax(1)\n",
        "        # D_mybest[:, k, :] = XTX[gamma[k], :]  # Same line as below, but significantly slower. (prob. due to the intermediate array creation)\n",
        "        torch.gather(XTX, 0, sets[k, :, None].expand(-1, XTX.shape[1]), out=D_mybest[:, k, :])\n",
        "        if k:\n",
        "            D_mybest_maxindices = D_mybest.permute(0, 2, 1)[torch.arange(D_mybest.shape[0], dtype=sets.dtype, device=sets.device), sets[k], :k]\n",
        "            torch.rsqrt(1 - innerp(D_mybest_maxindices),\n",
        "                        out=temp_F_k_k[:, 0])  # torch.exp(-1/2 * torch.log1p(-inp), temp_F_k_k[:, 0])\n",
        "            D_mybest_maxindices *= -temp_F_k_k  # minimal operations, exploit linearity\n",
        "            D_mybest[:, k, :] *= temp_F_k_k\n",
        "            D_mybest[:, k, :, None].baddbmm_(D_mybest[:, :k, :].permute(0, 2, 1), D_mybest_maxindices[:, :, None])\n",
        "\n",
        "\n",
        "        temp_a_F = temp_F_k_k * torch.gather(projections, 1, sets[k, :, None])\n",
        "        normr2 -= (temp_a_F * temp_a_F).squeeze(-1)\n",
        "        projections -= temp_a_F * D_mybest[:, k, :]\n",
        "        if inverse_cholesky:\n",
        "            a_F[k] = temp_a_F\n",
        "            if k:  # Could maybe get a speedup from triangular mat mul kernel.\n",
        "                torch.bmm(D_mybest_maxindices[:, None, :], F[:, :k, :], out=F[:, k, None, :])\n",
        "                F[:, k, k] = temp_F_k_k[..., 0]\n",
        "    else: # FIXME: else branch will not execute if n_nonzero_coefs=0, so solutions is undefined.\n",
        "        # Normal exit, used when tolerance=None.\n",
        "        if inverse_cholesky:\n",
        "            solutions = F.permute(0, 2, 1) @ a_F.squeeze(-1).transpose(1, 0)[:, :, None]\n",
        "        else:\n",
        "            # Solving the problem in the end without using inverse Cholesky.\n",
        "            AT = X.T[sets.T]\n",
        "            solutions = cholesky_solve(AT @ AT.permute(0, 2, 1), AT @ y.T[:, :, None])\n",
        "\n",
        "    return sets.t(), solutions, None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRHA7INejuWz"
      },
      "source": [
        "# Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIvbH9ewrBbu",
        "outputId": "cd473005-1bf6-445b-a0c1-f7f82af5e934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.optim import Adam\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from IPython.display import clear_output\n",
        "from transformers import logging\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "import sklearn\n",
        "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKthqrfspFXf"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/NLP-Final/'\n",
        "\n",
        "train_data = pd.read_csv(path + 'train.csv')\n",
        "test_data = pd.read_csv(path + 'test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG6l9XH-qw-Q",
        "outputId": "21c77fff-1150-480f-fafe-6e1ca6f2fe86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 2000, 500, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_data = train_data[:2000]\n",
        "test_data = test_data[:500]\n",
        "\n",
        "train_data = train_data.to_dict(orient='records')\n",
        "test_data = test_data.to_dict(orient='records')\n",
        "type(train_data)\n",
        "\n",
        "train_texts, train_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), train_data)))\n",
        "test_texts, test_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), test_data)))\n",
        "\n",
        "len(train_texts), len(train_labels), len(test_texts), len(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhIN1TIosy1W"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], train_texts))\n",
        "test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], test_texts))\n",
        "train_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, train_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "test_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, test_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "\n",
        "train_y = np.array(train_labels) == 'pos'\n",
        "test_y = np.array(test_labels) == 'pos'\n",
        "\n",
        "train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
        "test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DWoyuX7vBjC"
      },
      "outputs": [],
      "source": [
        "class BertBinaryClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertBinaryClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, tokens, masks=None):\n",
        "        output = self.bert(tokens, attention_mask=masks)\n",
        "        pooled_output = output.pooler_output\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIFgyz1iwBG6"
      },
      "outputs": [],
      "source": [
        "# bert_clf = BertBinaryClassifier()\n",
        "# bert_clf = bert_clf.cuda()\n",
        "# x = torch.tensor(train_tokens_ids[:3]).to(device)\n",
        "# y, pooled = bert_clf.bert(x)\n",
        "# y = bert_clf(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5UDUU7vyrTt"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 4\n",
        "EPOCHS = 10\n",
        "\n",
        "train_tokens_tensor = torch.tensor(train_tokens_ids)\n",
        "train_y_tensor = torch.tensor(train_y.reshape(-1, 1)).float()\n",
        "\n",
        "test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
        "test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()\n",
        "\n",
        "train_masks_tensor = torch.tensor(train_masks)\n",
        "test_masks_tensor = torch.tensor(test_masks)\n",
        "\n",
        "train_dataset = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_dataset = TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctRm2dN33r_M"
      },
      "outputs": [],
      "source": [
        "def train_model(model):\n",
        "  param_optimizer = list(model.sigmoid.named_parameters()) \n",
        "  optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "  optimizer = Adam(model.parameters(), lr=3e-6)\n",
        "  torch.cuda.empty_cache()   # Clearing Cache space for a fresh Model run\n",
        "\n",
        "  for epoch_num in range(EPOCHS):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for step_num, batch_data in enumerate(train_dataloader):\n",
        "        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "        print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')\n",
        "        logits = model(token_ids, masks)\n",
        "        \n",
        "        loss_func = nn.BCELoss()\n",
        "\n",
        "        batch_loss = loss_func(logits, labels)\n",
        "        train_loss += batch_loss.item()\n",
        "        \n",
        "        model.zero_grad()\n",
        "        batch_loss.backward()\n",
        "\n",
        "        clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "        print('Epoch: ', epoch_num + 1)\n",
        "        print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / BATCH_SIZE, train_loss / (step_num + 1)))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWz7U6X2ydWY"
      },
      "outputs": [],
      "source": [
        "def eval_model(model):\n",
        "  model.eval().to(device)\n",
        "  model_predicted = []\n",
        "  all_logits = []\n",
        "  with torch.no_grad():\n",
        "      for step_num, batch_data in enumerate(test_dataloader):\n",
        "          token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "\n",
        "          logits = model(token_ids, masks)\n",
        "          loss_func = nn.BCELoss()\n",
        "          loss = loss_func(logits, labels)\n",
        "          numpy_logits = logits.cpu().detach().numpy()\n",
        "          \n",
        "          model_predicted += list(numpy_logits[:, 0] > 0.5)\n",
        "          all_logits += list(numpy_logits[:, 0])\n",
        "\n",
        "          token_ids, masks, labels = tuple(t.to(\"cpu\") for t in batch_data) # PATCH- move back to cpu\n",
        "\n",
        "  print(classification_report(test_y, model_predicted))\n",
        "  model.to(\"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BG03F5BP4qUj"
      },
      "outputs": [],
      "source": [
        "def convert_model_state_to_zeros(model, model_state):\n",
        "  # print(st)\n",
        "  for name,x in model.named_parameters():\n",
        "  #  if \"intermediate.dense\" in name  or \"output.dense\" in name:\n",
        "  # if \"intermediate.dense\" in name or \"output.dense\" in name: # intermidiate is the feed forward part of the layer \n",
        "      model_state[name]  = model_state[name]*0\n",
        "  return model_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3j0Yugew3lm"
      },
      "outputs": [],
      "source": [
        "def print_layers_params(model, model_state):\n",
        "  # print(st)\n",
        "  for name,x in model.named_parameters():\n",
        "  #  if \"intermediate.dense\" in name  or \"output.dense\" in name:\n",
        "    if \"intermediate.dense\" in name: # intermidiate is the feed forward part of the layer \n",
        "      print(model_state[name])\n",
        "\n",
        "# print_layers_params(bert_clf, bert_clf.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVJ4nStWqfrp"
      },
      "outputs": [],
      "source": [
        "STATE_PATH = '/content/drive/MyDrive/NLP-Final/bert_state_w_finetuning'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert1 = BertBinaryClassifier()\n",
        "bert1.load_state_dict(torch.load(STATE_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q0qw9wfEJXl",
        "outputId": "b2ac7209-4e3e-48d7-a5d9-1b5509f807ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# #####RUN ALL BEFORE THIS LINE !! - CLICK \"RUN BEFORE\" ON THIS CELL //Ctrl+F8\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "iU8p-XsfEnN-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mopvGI8tD6tB"
      },
      "source": [
        "# Experiment - No Need for now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "dfbd201e45794dac85cfabb89d1330bc",
            "e6a161a4f107474cadd8739d195bd57a",
            "0578cbace9c646ccaa68cb2563c4b020",
            "065a1260d9dc4e9ab54b4a03abcded9f",
            "86922c1e29cb424ab2ba3dc2b8f75a44",
            "78afb763046a49a5b9c9184315cf67ed",
            "7ffa231c75be48ada3b6e93a66941c3c",
            "d8b9da45d07c4c6d91a6eea6228cf1f8",
            "28ddb55de40a4d50bf09946f80776a20",
            "021e21e0bb3841cdbb1a370cb97af91d",
            "3c886277a34d4a9887aa7118d3ddf9ac"
          ]
        },
        "id": "qvRxoZ1G4vTe",
        "outputId": "379b86a6-30ae-4773-fe73-0dec37118b5e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfbd201e45794dac85cfabb89d1330bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0101, -0.0017,  0.0130,  ..., -0.0537,  0.0137, -0.0192],\n",
            "        [-0.0604,  0.0104,  0.0648,  ..., -0.0486, -0.0277,  0.0070],\n",
            "        [-0.0147,  0.0428,  0.0398,  ..., -0.0082,  0.0114, -0.0275],\n",
            "        ...,\n",
            "        [-0.0500, -0.0660,  0.0270,  ..., -0.0131,  0.0041,  0.0068],\n",
            "        [ 0.0448, -0.0237,  0.0167,  ...,  0.0035,  0.0069,  0.0205],\n",
            "        [-0.0094,  0.0363,  0.0258,  ..., -0.0086,  0.0064,  0.0604]])\n"
          ]
        }
      ],
      "source": [
        "# regular eval\n",
        "bert_regular = BertBinaryClassifier()\n",
        "# bert_regular = bert_regular.cuda()\n",
        "regular_st = bert_regular.state_dict()\n",
        "print(regular_st[\"bert.encoder.layer.0.intermediate.dense.weight\"])\n",
        "\n",
        "# model= train_model(bert_regular)\n",
        "# regular_st = bert_regular.state_dict()\n",
        "# print(regular_st[\"bert.encoder.layer.0.intermediate.dense.weight\"])\n",
        "\n",
        "# eval_model(bert_regular)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjbba9cA8lyO"
      },
      "outputs": [],
      "source": [
        "# # save BERT's state after finetuning\n",
        "# STATE_PATH = '/content/drive/MyDrive/NLP-Final/bert_state_w_finetuning'\n",
        "# regular_st = bert_regular.state_dict()\n",
        "# torch.save(regular_st, STATE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntTuBRdkCNW7"
      },
      "outputs": [],
      "source": [
        "# bert_check = BertBinaryClassifier()\n",
        "# bert_check = bert_check.cuda()\n",
        "# bert_check.load_state_dict(torch.load(STATE_PATH))\n",
        "# eval_model(bert_check)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUuoKPRL_ruo"
      },
      "outputs": [],
      "source": [
        "# # convert ff params to zeros and eval\n",
        "# bert_zeros = BertBinaryClassifier()\n",
        "# bert_zeros = bert_zeros.cuda()\n",
        "# zeros_st = convert_model_state_to_zeros(bert_zeros, bert_zeros.state_dict())\n",
        "# bert_zeros.load_state_dict(zeros_st)\n",
        "# zeros_st = bert_zeros.state_dict()\n",
        "# print(zeros_st[\"bert.encoder.layer.0.intermediate.dense.weight\"])\n",
        "# print(zeros_st[\"bert.encoder.layer.0.output.dense.weight\"])\n",
        "# eval_model(bert_zeros) # eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzVT5tI_YWCI"
      },
      "source": [
        "# Sparsity with SKlearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "81IK3eQHJTtM",
        "outputId": "61de9c74-31f7-40c7-efc5-1e9ec9cfe6ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
            "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-3bd05b1ec033>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mn_non_zero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrthogonalMatchingPursuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_omp.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    751\u001b[0m                 \u001b[0mprecompute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m                 \u001b[0mcopy_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m                 \u001b[0mreturn_n_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             )\n\u001b[1;32m    755\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_omp.py\u001b[0m in \u001b[0;36morthogonal_mp\u001b[0;34m(X, y, n_nonzero_coefs, tol, precompute, copy_X, return_path, return_n_iter)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         out = _cholesky_omp(\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nonzero_coefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         )\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_omp.py\u001b[0m in \u001b[0;36m_cholesky_omp\u001b[0;34m(X, y, n_nonzero_coefs, tol, copy_X, return_path)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_active\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m# Updates the Cholesky decomposition of X' X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_active\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_active\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_active\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             linalg.solve_triangular(\n\u001b[1;32m    105\u001b[0m                 \u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_active\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_active\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "bert_sparse = BertBinaryClassifier()\n",
        "bert_sparse = bert_sparse.cuda()\n",
        "bert_sparse.load_state_dict(torch.load(STATE_PATH))\n",
        "# eval_model(bert_sparse)\n",
        "\n",
        "# find x that minimize ||keys - Embeddings*x||, given sparsity level for x\n",
        "# meaning, the best approx for: keys = E*x\n",
        "# replace this x with original keys\n",
        "emb = bert_sparse.bert.get_input_embeddings()\n",
        "bert_sparse_st = bert_sparse.bert.state_dict()\n",
        "\n",
        "X = emb.weight.cpu().detach().numpy()\n",
        "y = bert_sparse_st[\"encoder.layer.0.intermediate.dense.weight\"].cpu().detach().numpy()\n",
        "print(type(X))\n",
        "print(type(y))\n",
        "\n",
        "n_features = X.shape[1]\n",
        "n_non_zero = max(int(0.1 * n_features), 1)\n",
        "\n",
        "mp = OrthogonalMatchingPursuit(normalize=False).fit(X.T, y.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ggwNldrYRtp"
      },
      "outputs": [],
      "source": [
        "# save mp!!!\n",
        "print(mp)\n",
        "print(mp.size())\n",
        "\n",
        "# Replace! + save mp!\n",
        "bert_sparse_st[\"encoder.layer.0.intermediate.dense.weight\"] = mp\n",
        "bert_sparse.bert.load_state_dict(bert_sparse_st)\n",
        "bert_sparse_st = bert_sparse.state_dict()\n",
        "torch.save(bert_sparse_st, '/content/drive/MyDrive/NLP-Final/bert_state_w_mp_0.1')\n",
        "eval_model(bert_sparse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa-ia6e8EPIr"
      },
      "source": [
        "# Sparsity with OMP - DEV and CHECK"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert1 = BertBinaryClassifier()\n",
        "bert1.load_state_dict(torch.load(STATE_PATH))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym64bTXE19FP",
        "outputId": "64213e0e-02aa-43d0-da15-bc70d4785560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GpimdBKk1d0"
      },
      "outputs": [],
      "source": [
        "bert1 = BertBinaryClassifier()\n",
        "bert1 = bert1.cuda()\n",
        "bert1.load_state_dict(torch.load(STATE_PATH))\n",
        "\n",
        "emb1 = bert1.bert.get_input_embeddings()\n",
        "bert1_st = bert1.bert.state_dict()\n",
        "\n",
        "X = emb1.weight.cpu().detach().to(device)\n",
        "y = bert1_st[\"encoder.layer.0.attention.output.dense.weight\"].detach().to(device)\n",
        "\n",
        "n_features = X.shape[1]\n",
        "n_non_zero = max(int(0.1 * n_features), 1)\n",
        "\n",
        "xes = run_omp(X.T,  y.T, n_non_zero,alg='v0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHKpuGRVsQ3x"
      },
      "outputs": [],
      "source": [
        "xes.size()\n",
        "bert1_st[\"encoder.layer.0.attention.output.dense.weight\"] = xes\n",
        "bert1.bert.load_state_dict(bert1_st)\n",
        "eval_model(bert1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = bert1_st[\"encoder.layer.2.intermediate.dense.weight\"].cpu().numpy()\n"
      ],
      "metadata": {
        "id": "6RpYwNtULC3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "mp = OrthogonalMatchingPursuit(normalize=False).fit(X.T.cpu(), y.T)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZQF4z5oKsVj",
        "outputId": "580a6ccd-66f9-432e-f6ff-f7f587419901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30522, 768])\n",
            "(3072, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
            "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# no replace\n",
        "eval_model(bert1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evtJJg5mxBp6",
        "outputId": "7e008636-661f-4187-bf1f-c94174561c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.93      0.90      0.91       246\n",
            "        True       0.91      0.93      0.92       254\n",
            "\n",
            "    accuracy                           0.92       500\n",
            "   macro avg       0.92      0.92      0.92       500\n",
            "weighted avg       0.92      0.92      0.92       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# layer 2 intermediate replace\n",
        "j = mp.predict(X.T.cpu())\n",
        "bert1_st[\"encoder.layer.2.intermediate.dense.weight\"]  = torch.Tensor(j.T)\n",
        "bert1.bert.load_state_dict(bert1_st)\n",
        "eval_model(bert1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myd6U7FUb_9J",
        "outputId": "d9dcc439-3f05-4801-9d01-5d91960679ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.93      0.87      0.90       246\n",
            "        True       0.88      0.94      0.91       254\n",
            "\n",
            "    accuracy                           0.90       500\n",
            "   macro avg       0.91      0.90      0.90       500\n",
            "weighted avg       0.91      0.90      0.90       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(bert1, '/content/drive/MyDrive/NLP-Final/bert_state_layer2_intermediate_sparse')\n",
        "# torch.save(bert1, '/content/drive/MyDrive/NLP-Final/bert_state_layer0_attention_output_dense_sparse')\n"
      ],
      "metadata": {
        "id": "X9jjSRm7olLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# attention output replace\n",
        "j = mp.predict(X.T.cpu())\n",
        "bert1_st[\"encoder.layer.0.attention.output.dense.weight\"]  = torch.Tensor(j.T)\n",
        "bert1.bert.load_state_dict(bert1_st)\n",
        "eval_model(bert1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDxnQZMkY02q",
        "outputId": "29ae6b20-5a41-4b84-a999-a9858febcae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.92      0.90      0.91       246\n",
            "        True       0.90      0.93      0.92       254\n",
            "\n",
            "    accuracy                           0.91       500\n",
            "   macro avg       0.91      0.91      0.91       500\n",
            "weighted avg       0.91      0.91      0.91       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqgZKLP7QOrS",
        "outputId": "22eee973-4ff1-4426-db1e-a6a80592d282"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:112: UserWarning: torch.cholesky is deprecated in favor of torch.linalg.cholesky and will be removed in a future PyTorch release.\n",
            "L = torch.cholesky(A)\n",
            "should be replaced with\n",
            "L = torch.linalg.cholesky(A)\n",
            "and\n",
            "U = torch.cholesky(A, upper=True)\n",
            "should be replaced with\n",
            "U = torch.linalg.cholesky(A).transpose(-2, -1).conj().\n",
            "This transform will produce equivalent results for all valid (symmetric positive definite) inputs. (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1285.)\n"
          ]
        }
      ],
      "source": [
        "# bert1.to(\"cpu\")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "emb1 = bert1.bert.get_input_embeddings()\n",
        "bert1_st = bert1.bert.state_dict()\n",
        "\n",
        "X_tensor = emb1.weight.detach().to(device)\n",
        "y_tensor = bert1_st[\"encoder.layer.2.intermediate.dense.weight\"].detach().to(device)\n",
        "\n",
        "num_features = X_tensor.shape[1]\n",
        "n_non_zero = max(int(0.1 * num_features), 1)\n",
        "\n",
        "# xes = run_omp(X_tensor.T.cpu(),  y_tensor.cpu(), n_non_zero, alg='v0')\n",
        "xes = run_omp(X_tensor.T,  y_tensor, n_non_zero)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(xes @ X_tensor).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He0aaUv66j2z",
        "outputId": "a4a7be7e-4e4e-4c73-e70e-06e729d4e944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3072, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# layer 2 intermediate replace - OMP FAST\n",
        "j = xes @ X_tensor\n",
        "bert1_st[\"encoder.layer.2.intermediate.dense.weight\"]  = j\n",
        "bert1.bert.load_state_dict(bert1_st)\n",
        "eval_model(bert1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vErmiZr97XUd",
        "outputId": "112e05a3-30e5-4857-80bc-e813a535c9ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.84      0.96      0.90       246\n",
            "        True       0.95      0.83      0.89       254\n",
            "\n",
            "    accuracy                           0.89       500\n",
            "   macro avg       0.90      0.89      0.89       500\n",
            "weighted avg       0.90      0.89      0.89       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# #####Run only one of the sections Below due to GPU Memory Runout"
      ],
      "metadata": {
        "id": "cPDY2YliLJCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#10% of Coefficients are Non-zero - TESTS"
      ],
      "metadata": {
        "id": "u4F6aWkzD8ON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERT Test - Replace each layer independently**\n",
        "\n",
        "```\n",
        "    bert1_st = bert1.bert.state_dict() # Bert model state dictionary\n",
        "    y_tensor = bert1_st[f\"encoder.layer.{i-1}.intermediate.dense.weight\"].detach().to(device) # get weights for ith ff layer\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "AlANW1sFC6YL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace every state independently\n",
        "emb1 = bert1.bert.get_input_embeddings() # embeddings\n",
        "bert1_st = bert1.bert.state_dict() # Bert model state dictionary\n",
        "\n",
        "X_tensor = emb1.weight.detach().to(device) \n",
        "num_features = X_tensor.shape[1]\n",
        "n_non_zero = max(int(0.1 * num_features), 1) # 10% of X num of features\n",
        "\n",
        "for i in range(13):\n",
        "  torch.cuda.empty_cache() # Clear memory\n",
        "  bert1.load_state_dict(torch.load(STATE_PATH)) # load first the original weights\n",
        "\n",
        "  if i == 0:\n",
        "    print(\"Results Before Replacement\")\n",
        "    eval_model(bert1)\n",
        "    continue\n",
        "\n",
        "  bert1_st = bert1.bert.state_dict() # Bert model state dictionary\n",
        "  y_tensor = bert1_st[f\"encoder.layer.{i-1}.intermediate.dense.weight\"].detach().to(device) # get weights for ith ff layer\n",
        "\n",
        "  xes = run_omp(X_tensor.T,  y_tensor, n_non_zero) # run fast OMP\n",
        "\n",
        "  temp_weights = xes @ X_tensor # matrix mult to get the weights\n",
        "\n",
        "  bert1_st[f\"encoder.layer.{i-1}.intermediate.dense.weight\"]  = temp_weights\n",
        "  bert1.bert.load_state_dict(bert1_st)\n",
        "  print(f\"Results for layer-{i-1} Weights Replacement\")\n",
        "  eval_model(bert1)\n",
        "\n",
        "  y_tensor.to(\"cpu\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sioqAT8zCryd",
        "outputId": "cef01fc7-ecd7-4b5a-fad9-a79d14a7284d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results Before Replacement\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.93      0.90      0.91       246\n",
            "        True       0.91      0.93      0.92       254\n",
            "\n",
            "    accuracy                           0.92       500\n",
            "   macro avg       0.92      0.92      0.92       500\n",
            "weighted avg       0.92      0.92      0.92       500\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:112: UserWarning: torch.cholesky is deprecated in favor of torch.linalg.cholesky and will be removed in a future PyTorch release.\n",
            "L = torch.cholesky(A)\n",
            "should be replaced with\n",
            "L = torch.linalg.cholesky(A)\n",
            "and\n",
            "U = torch.cholesky(A, upper=True)\n",
            "should be replaced with\n",
            "U = torch.linalg.cholesky(A).transpose(-2, -1).conj().\n",
            "This transform will produce equivalent results for all valid (symmetric positive definite) inputs. (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1285.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for layer-0 Weights Replacement]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.91      0.74      0.82       246\n",
            "        True       0.79      0.93      0.85       254\n",
            "\n",
            "    accuracy                           0.84       500\n",
            "   macro avg       0.85      0.83      0.83       500\n",
            "weighted avg       0.85      0.84      0.83       500\n",
            "\n",
            "Results for layer-1 Weights Replacement]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.93      0.85      0.89       246\n",
            "        True       0.87      0.94      0.90       254\n",
            "\n",
            "    accuracy                           0.90       500\n",
            "   macro avg       0.90      0.90      0.90       500\n",
            "weighted avg       0.90      0.90      0.90       500\n",
            "\n",
            "Results for layer-2 Weights Replacement]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.84      0.96      0.90       246\n",
            "        True       0.95      0.83      0.89       254\n",
            "\n",
            "    accuracy                           0.89       500\n",
            "   macro avg       0.90      0.89      0.89       500\n",
            "weighted avg       0.90      0.89      0.89       500\n",
            "\n",
            "Results for layer-3 Weights Replacement]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      0.94      0.92       246\n",
            "        True       0.94      0.89      0.92       254\n",
            "\n",
            "    accuracy                           0.92       500\n",
            "   macro avg       0.92      0.92      0.92       500\n",
            "weighted avg       0.92      0.92      0.92       500\n",
            "\n",
            "Results for layer-4 Weights Replacement]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      0.91      0.91       246\n",
            "        True       0.91      0.90      0.91       254\n",
            "\n",
            "    accuracy                           0.91       500\n",
            "   macro avg       0.91      0.91      0.91       500\n",
            "weighted avg       0.91      0.91      0.91       500\n",
            "\n",
            "Results for layer-5 Weights Replacement]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.89      0.92      0.90       246\n",
            "        True       0.92      0.89      0.90       254\n",
            "\n",
            "    accuracy                           0.90       500\n",
            "   macro avg       0.90      0.90      0.90       500\n",
            "weighted avg       0.90      0.90      0.90       500\n",
            "\n",
            "Results for layer-6 Weights Replacement]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      0.93      0.91       246\n",
            "        True       0.93      0.90      0.91       254\n",
            "\n",
            "    accuracy                           0.91       500\n",
            "   macro avg       0.91      0.91      0.91       500\n",
            "weighted avg       0.91      0.91      0.91       500\n",
            "\n",
            "Results for layer-7 Weights Replacement]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.91      0.90      0.91       246\n",
            "        True       0.91      0.92      0.91       254\n",
            "\n",
            "    accuracy                           0.91       500\n",
            "   macro avg       0.91      0.91      0.91       500\n",
            "weighted avg       0.91      0.91      0.91       500\n",
            "\n",
            "Results for layer-8 Weights Replacement]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.93      0.88      0.90       246\n",
            "        True       0.89      0.93      0.91       254\n",
            "\n",
            "    accuracy                           0.91       500\n",
            "   macro avg       0.91      0.91      0.91       500\n",
            "weighted avg       0.91      0.91      0.91       500\n",
            "\n",
            "Results for layer-9 Weights Replacement]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.93      0.88      0.91       246\n",
            "        True       0.89      0.94      0.91       254\n",
            "\n",
            "    accuracy                           0.91       500\n",
            "   macro avg       0.91      0.91      0.91       500\n",
            "weighted avg       0.91      0.91      0.91       500\n",
            "\n",
            "Results for layer-10 Weights Replacement]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.92      0.88      0.90       246\n",
            "        True       0.89      0.93      0.91       254\n",
            "\n",
            "    accuracy                           0.91       500\n",
            "   macro avg       0.91      0.91      0.91       500\n",
            "weighted avg       0.91      0.91      0.91       500\n",
            "\n",
            "Results for layer-11 Weights Replacement]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.93      0.90      0.91       246\n",
            "        True       0.91      0.93      0.92       254\n",
            "\n",
            "    accuracy                           0.92       500\n",
            "   macro avg       0.92      0.92      0.92       500\n",
            "weighted avg       0.92      0.92      0.92       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERT Test - Replace layers one by one together**\n",
        "\n",
        "```\n",
        "    y_tensor = bert1_st[f\"encoder.layer.{i-1}.intermediate.dense.weight\"].detach().to(device) # get weights for ith ff layer\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "fWaZn2XjDXL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add replace and test -  in every step \n",
        "emb1 = bert1.bert.get_input_embeddings() # embeddings\n",
        "bert1_st = bert1.bert.state_dict() # Bert model state dictionary\n",
        "\n",
        "X_tensor = emb1.weight.detach().to(device) \n",
        "num_features = X_tensor.shape[1]\n",
        "n_non_zero = max(int(0.1 * num_features), 1) # 10% of X num of features\n",
        "\n",
        "for i in range(13):\n",
        "  torch.cuda.empty_cache() # Clear memory\n",
        "  bert1.load_state_dict(torch.load(STATE_PATH)) # load first the original weights\n",
        "\n",
        "  if i == 0:\n",
        "    print(\"Results Before Replacement\")\n",
        "    eval_model(bert1)\n",
        "    continue\n",
        "\n",
        "  # bert1_st is updated every step\n",
        "  y_tensor = bert1_st[f\"encoder.layer.{i-1}.intermediate.dense.weight\"].detach().to(device) # get weights for ith ff layer\n",
        "\n",
        "  xes = run_omp(X_tensor.T,  y_tensor, n_non_zero) # run fast OMP\n",
        "\n",
        "  temp_weights = xes @ X_tensor # matrix mult to get the weights\n",
        "\n",
        "  bert1_st[f\"encoder.layer.{i-1}.intermediate.dense.weight\"]  = temp_weights\n",
        "  bert1.bert.load_state_dict(bert1_st)\n",
        "  print(f\"Results for Replacing all the layers up to layer-{i-1} (included)\")\n",
        "  eval_model(bert1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2o0TSXg7zwr",
        "outputId": "00725c2f-6d51-4d5f-d030-be1acca911b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results Before Replacement\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.93      0.90      0.91       246\n",
            "        True       0.91      0.93      0.92       254\n",
            "\n",
            "    accuracy                           0.92       500\n",
            "   macro avg       0.92      0.92      0.92       500\n",
            "weighted avg       0.92      0.92      0.92       500\n",
            "\n",
            "Results for Replacing all the layers up to layer-0 (included)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.91      0.74      0.82       246\n",
            "        True       0.79      0.93      0.85       254\n",
            "\n",
            "    accuracy                           0.84       500\n",
            "   macro avg       0.85      0.83      0.83       500\n",
            "weighted avg       0.85      0.84      0.83       500\n",
            "\n",
            "Results for Replacing all the layers up to layer-1 (included)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.77      0.89      0.83       246\n",
            "        True       0.88      0.75      0.81       254\n",
            "\n",
            "    accuracy                           0.82       500\n",
            "   macro avg       0.83      0.82      0.82       500\n",
            "weighted avg       0.83      0.82      0.82       500\n",
            "\n",
            "Results for Replacing all the layers up to layer-2 (included)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.76      0.85      0.80       246\n",
            "        True       0.83      0.75      0.79       254\n",
            "\n",
            "    accuracy                           0.80       500\n",
            "   macro avg       0.80      0.80      0.80       500\n",
            "weighted avg       0.80      0.80      0.80       500\n",
            "\n",
            "Results for Replacing all the layers up to layer-3 (included)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.83      0.67      0.74       246\n",
            "        True       0.73      0.87      0.79       254\n",
            "\n",
            "    accuracy                           0.77       500\n",
            "   macro avg       0.78      0.77      0.77       500\n",
            "weighted avg       0.78      0.77      0.77       500\n",
            "\n",
            "Results for Replacing all the layers up to layer-4 (included)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.86      0.59      0.70       246\n",
            "        True       0.69      0.91      0.78       254\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.77      0.75      0.74       500\n",
            "weighted avg       0.77      0.75      0.74       500\n",
            "\n",
            "Results for Replacing all the layers up to layer-5 (included)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.91      0.40      0.56       246\n",
            "        True       0.62      0.96      0.76       254\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.77      0.68      0.66       500\n",
            "weighted avg       0.76      0.69      0.66       500\n",
            "\n",
            "Results for Replacing all the layers up to layer-6 (included)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.86      0.07      0.13       246\n",
            "        True       0.52      0.99      0.68       254\n",
            "\n",
            "    accuracy                           0.54       500\n",
            "   macro avg       0.69      0.53      0.41       500\n",
            "weighted avg       0.69      0.54      0.41       500\n",
            "\n",
            "Results for Replacing all the layers up to layer-7 (included)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.93      0.11      0.19       246\n",
            "        True       0.53      0.99      0.69       254\n",
            "\n",
            "    accuracy                           0.56       500\n",
            "   macro avg       0.73      0.55      0.44       500\n",
            "weighted avg       0.73      0.56      0.45       500\n",
            "\n",
            "Results for Replacing all the layers up to layer-8 (included)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.94      0.39      0.55       246\n",
            "        True       0.62      0.98      0.76       254\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.78      0.68      0.66       500\n",
            "weighted avg       0.78      0.69      0.66       500\n",
            "\n",
            "Results for Replacing all the layers up to layer-9 (included)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.94      0.41      0.57       246\n",
            "        True       0.63      0.98      0.77       254\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.79      0.69      0.67       500\n",
            "weighted avg       0.78      0.70      0.67       500\n",
            "\n",
            "Results for Replacing all the layers up to layer-10 (included)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.97      0.28      0.44       246\n",
            "        True       0.59      0.99      0.74       254\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.78      0.64      0.59       500\n",
            "weighted avg       0.78      0.64      0.59       500\n",
            "\n",
            "Results for Replacing all the layers up to layer-11 (included)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.91      0.33      0.48       246\n",
            "        True       0.60      0.97      0.74       254\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.75      0.65      0.61       500\n",
            "weighted avg       0.75      0.65      0.61       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Different Sparsity Levels - Run Alone - No GPU Memory for all the EXP together - TESTS"
      ],
      "metadata": {
        "id": "POS_ksPJJkrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERT Test - Replace only for layer 0 and change num of Non Zero Coefficients**\n",
        "\n",
        "\n",
        "```\n",
        "  # Change ratio of non_zero_coef each iteration\n",
        "  n_non_zero = max(int(ratio * num_features), 1) # ratio of X num of features\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "V5iOxfYvH1Vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10%-30%\n",
        "emb1 = bert1.bert.get_input_embeddings() # embeddings\n",
        "bert1_st = bert1.bert.state_dict() # Bert model state dictionary\n",
        "\n",
        "X_tensor = emb1.weight.detach().to(device) \n",
        "num_features = X_tensor.shape[1]\n",
        "\n",
        "for i, ratio in enumerate(np.linspace(0.0, 0.3, 4)):\n",
        "  # Change ratio of non_zero_coef each iteration\n",
        "  n_non_zero = max(int(ratio * num_features), 1) # ratio of X num of features\n",
        "  torch.cuda.empty_cache() # Clear memory\n",
        "  \n",
        "  bert1.load_state_dict(torch.load(STATE_PATH)) # load first the original weights\n",
        "\n",
        "  if i == 0: # print baseline results first\n",
        "    print(\"Results Before Replacement\")\n",
        "    eval_model(bert1)\n",
        "    continue\n",
        "\n",
        "  bert1_st = bert1.bert.state_dict() # Bert model state dictionary\n",
        "  y_tensor = bert1_st[f\"encoder.layer.0.intermediate.dense.weight\"].detach().to(device) # get weights for ith ff layer\n",
        "\n",
        "  xes = run_omp(X_tensor.T,  y_tensor, n_non_zero) # run fast OMP\n",
        "\n",
        "  temp_weights = xes @ X_tensor # matrix mult to get the weights\n",
        "\n",
        "  bert1_st[f\"encoder.layer.0.intermediate.dense.weight\"]  = temp_weights\n",
        "  bert1.bert.load_state_dict(bert1_st)\n",
        "  print(f\"Results for layer-0 Weights Replacement with {100*ratio:.2f}% Non-Zero Coefficients\")\n",
        "  eval_model(bert1)\n",
        "\n",
        "  y_tensor.to(\"cpu\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwd200vV-oMo",
        "outputId": "dce08c81-92b7-4bab-da95-5ebce3fa6e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results Before Replacement\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.93      0.90      0.91       246\n",
            "        True       0.91      0.93      0.92       254\n",
            "\n",
            "    accuracy                           0.92       500\n",
            "   macro avg       0.92      0.92      0.92       500\n",
            "weighted avg       0.92      0.92      0.92       500\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:112: UserWarning: torch.cholesky is deprecated in favor of torch.linalg.cholesky and will be removed in a future PyTorch release.\n",
            "L = torch.cholesky(A)\n",
            "should be replaced with\n",
            "L = torch.linalg.cholesky(A)\n",
            "and\n",
            "U = torch.cholesky(A, upper=True)\n",
            "should be replaced with\n",
            "U = torch.linalg.cholesky(A).transpose(-2, -1).conj().\n",
            "This transform will produce equivalent results for all valid (symmetric positive definite) inputs. (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1285.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for layer-0 Weights Replacement with 10.00% Non-Zero Coefficients\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.91      0.74      0.82       246\n",
            "        True       0.79      0.93      0.85       254\n",
            "\n",
            "    accuracy                           0.84       500\n",
            "   macro avg       0.85      0.83      0.83       500\n",
            "weighted avg       0.85      0.84      0.83       500\n",
            "\n",
            "Results for layer-0 Weights Replacement with 20.00% Non-Zero Coefficients\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.94      0.83      0.88       246\n",
            "        True       0.85      0.94      0.90       254\n",
            "\n",
            "    accuracy                           0.89       500\n",
            "   macro avg       0.90      0.89      0.89       500\n",
            "weighted avg       0.89      0.89      0.89       500\n",
            "\n",
            "Results for layer-0 Weights Replacement with 30.00% Non-Zero Coefficients\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.92      0.87      0.90       246\n",
            "        True       0.88      0.93      0.91       254\n",
            "\n",
            "    accuracy                           0.90       500\n",
            "   macro avg       0.90      0.90      0.90       500\n",
            "weighted avg       0.90      0.90      0.90       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 40%-60%\n",
        "emb1 = bert1.bert.get_input_embeddings() # embeddings\n",
        "bert1_st = bert1.bert.state_dict() # Bert model state dictionary\n",
        "\n",
        "X_tensor = emb1.weight.detach().to(device) \n",
        "num_features = X_tensor.shape[1]\n",
        "\n",
        "for i, ratio in enumerate(np.linspace(0.3, 0.6, 4)):\n",
        "  bert1.to(\"cpu\")  \n",
        "  # Change ratio of non_zero_coef each iteration\n",
        "  n_non_zero = max(int(ratio * num_features), 1) # ratio of X num of features\n",
        "  torch.cuda.empty_cache() # Clear memory\n",
        "  \n",
        "  bert1.load_state_dict(torch.load(STATE_PATH)) # load first the original weights\n",
        "\n",
        "  if i == 0: # print baseline results first\n",
        "    print(\"Results Before Replacement\")\n",
        "    eval_model(bert1)\n",
        "    continue\n",
        "\n",
        "  bert1_st = bert1.bert.state_dict() # Bert model state dictionary\n",
        "  y_tensor = bert1_st[f\"encoder.layer.0.intermediate.dense.weight\"].detach().to(device) # get weights for ith ff layer\n",
        "\n",
        "  xes = run_omp(X_tensor.T,  y_tensor, n_non_zero) # run fast OMP\n",
        "\n",
        "  temp_weights = xes @ X_tensor # matrix mult to get the weights\n",
        "\n",
        "  bert1_st[f\"encoder.layer.0.intermediate.dense.weight\"]  = temp_weights\n",
        "  bert1.bert.load_state_dict(bert1_st)\n",
        "  print(f\"Results for layer-0 Weights Replacement with {100*ratio:.2f}% Non-Zero Coefficients\")\n",
        "  eval_model(bert1)\n",
        "\n",
        "  y_tensor.to(\"cpu\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        },
        "id": "VsQabtdmKans",
        "outputId": "1e95e102-7e09-4a4d-c973-f74d7cfd8204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results Before Replacement\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.93      0.90      0.91       246\n",
            "        True       0.91      0.93      0.92       254\n",
            "\n",
            "    accuracy                           0.92       500\n",
            "   macro avg       0.92      0.92      0.92       500\n",
            "weighted avg       0.92      0.92      0.92       500\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:112: UserWarning: torch.cholesky is deprecated in favor of torch.linalg.cholesky and will be removed in a future PyTorch release.\n",
            "L = torch.cholesky(A)\n",
            "should be replaced with\n",
            "L = torch.linalg.cholesky(A)\n",
            "and\n",
            "U = torch.cholesky(A, upper=True)\n",
            "should be replaced with\n",
            "U = torch.linalg.cholesky(A).transpose(-2, -1).conj().\n",
            "This transform will produce equivalent results for all valid (symmetric positive definite) inputs. (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1285.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for layer-0 Weights Replacement with 40.00% Non-Zero Coefficients\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.92      0.89      0.90       246\n",
            "        True       0.90      0.93      0.91       254\n",
            "\n",
            "    accuracy                           0.91       500\n",
            "   macro avg       0.91      0.91      0.91       500\n",
            "weighted avg       0.91      0.91      0.91       500\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-718210305bea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0my_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert1_st\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"encoder.layer.0.intermediate.dense.weight\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get weights for ith ff layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_omp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_non_zero\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# run fast OMP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mtemp_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxes\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX_tensor\u001b[0m \u001b[0;31m# matrix mult to get the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-30b01b536fcf>\u001b[0m in \u001b[0;36mrun_omp\u001b[0;34m(X, y, n_nonzero_coefs, precompute, tol, normalize, fit_intercept, alg)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# If n_nonzero_coefs is equal to M, one should just return lstsq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0malg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'naive'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0msets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0momp_naive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nonzero_coefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_nonzero_coefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXTX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecompute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0malg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'v0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0msets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0momp_v0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nonzero_coefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_nonzero_coefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXTX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecompute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-30b01b536fcf>\u001b[0m in \u001b[0;36momp_naive\u001b[0;34m(X, y, n_nonzero_coefs, tol, XTX)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mATA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mATA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Copy lower triangle to upper triangle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0msolutions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcholesky_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mATy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;31m# FINALLY, GET NEW RESIDUAL r=y-Ax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-30b01b536fcf>\u001b[0m in \u001b[0;36mcholesky_solve\u001b[0;34m(ATA, ATy)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mATA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mATy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mATy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mATA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mATy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mATy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mATA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mATy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.56 GiB (GPU 0; 14.76 GiB total capacity; 11.02 GiB already allocated; 1.56 GiB free; 11.74 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "XXhsEvzIjlZP",
        "ZRHA7INejuWz",
        "mopvGI8tD6tB",
        "XzVT5tI_YWCI",
        "pa-ia6e8EPIr",
        "u4F6aWkzD8ON"
      ],
      "name": "BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dfbd201e45794dac85cfabb89d1330bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6a161a4f107474cadd8739d195bd57a",
              "IPY_MODEL_0578cbace9c646ccaa68cb2563c4b020",
              "IPY_MODEL_065a1260d9dc4e9ab54b4a03abcded9f"
            ],
            "layout": "IPY_MODEL_86922c1e29cb424ab2ba3dc2b8f75a44"
          }
        },
        "e6a161a4f107474cadd8739d195bd57a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78afb763046a49a5b9c9184315cf67ed",
            "placeholder": "",
            "style": "IPY_MODEL_7ffa231c75be48ada3b6e93a66941c3c",
            "value": "Downloading: 100%"
          }
        },
        "0578cbace9c646ccaa68cb2563c4b020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8b9da45d07c4c6d91a6eea6228cf1f8",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28ddb55de40a4d50bf09946f80776a20",
            "value": 440473133
          }
        },
        "065a1260d9dc4e9ab54b4a03abcded9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_021e21e0bb3841cdbb1a370cb97af91d",
            "placeholder": "",
            "style": "IPY_MODEL_3c886277a34d4a9887aa7118d3ddf9ac",
            "value": " 420M/420M [00:08&lt;00:00, 51.8MB/s]"
          }
        },
        "86922c1e29cb424ab2ba3dc2b8f75a44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78afb763046a49a5b9c9184315cf67ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ffa231c75be48ada3b6e93a66941c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8b9da45d07c4c6d91a6eea6228cf1f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28ddb55de40a4d50bf09946f80776a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "021e21e0bb3841cdbb1a370cb97af91d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c886277a34d4a9887aa7118d3ddf9ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}