{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Roberta.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPLs4HxKDOLhylZ/MUZoZMn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install transformers\n","import torch\n","from torch import nn\n","import pandas as pd\n","import numpy as np\n","from keras.preprocessing.sequence import pad_sequences\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from transformers import RobertaTokenizer, RobertaForSequenceClassification\n","from sklearn.metrics import classification_report\n","from torch.optim import Adam\n","from torch.nn.utils import clip_grad_norm_\n","from IPython.display import clear_output\n","from transformers import logging\n","logging.set_verbosity_error()\n","\n","import sklearn\n","from sklearn.linear_model import OrthogonalMatchingPursuit\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pB_jQE8fmvZ-","executionInfo":{"status":"ok","timestamp":1650416663204,"user_tz":-180,"elapsed":17545,"user":{"displayName":"Yuvi Cohen","userId":"06088571010261123017"}},"outputId":"dcd27a76-b61a-4149-b804-2ed4daee55db"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","cuda\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1d_VSP0mhF4","executionInfo":{"status":"ok","timestamp":1650416664479,"user_tz":-180,"elapsed":1281,"user":{"displayName":"Yuvi Cohen","userId":"06088571010261123017"}},"outputId":"1e404765-a8c5-4f39-8b1f-5a187a47efc7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2000, 2000, 500, 500)"]},"metadata":{},"execution_count":2}],"source":["path = '/content/drive/MyDrive/NLP-Final/'\n","\n","train_data = pd.read_csv(path + 'train.csv')\n","test_data = pd.read_csv(path + 'test.csv')\n","\n","train_data = train_data[:2000]\n","test_data = test_data[:500]\n","\n","train_data = train_data.to_dict(orient='records')\n","test_data = test_data.to_dict(orient='records')\n","type(train_data)\n","\n","train_texts, train_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), train_data)))\n","test_texts, test_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), test_data)))\n","\n","len(train_texts), len(train_labels), len(test_texts), len(test_labels)"]},{"cell_type":"code","source":["BATCH_SIZE = 4\n","\n","def process_data(tokenizer):\n","    train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], train_texts))\n","    test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], test_texts))\n","    train_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, train_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n","    test_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, test_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n","\n","    train_y = np.array(train_labels) == 'pos'\n","    test_y = np.array(test_labels) == 'pos'\n","    # test_y = np.append(test_y, np.array(test_labels) != 'pos')\n","\n","    train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n","    test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]\n","    \n","    train_tokens_tensor = torch.tensor(train_tokens_ids)\n","    train_y_tensor = torch.tensor(train_y.reshape(-1, 1)).float()\n","\n","    test_tokens_tensor = torch.tensor(test_tokens_ids)\n","    test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()\n","\n","    train_masks_tensor = torch.tensor(train_masks)\n","    test_masks_tensor = torch.tensor(test_masks)\n","\n","    train_dataset = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n","    train_sampler = RandomSampler(train_dataset)\n","    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n","\n","    test_dataset = TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n","    test_sampler = SequentialSampler(test_dataset)\n","    test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)\n","    \n","    return train_dataloader, test_dataloader, test_y"],"metadata":{"id":"dDgKVk8amoHY","executionInfo":{"status":"ok","timestamp":1650416664480,"user_tz":-180,"elapsed":7,"user":{"displayName":"Yuvi Cohen","userId":"06088571010261123017"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 10\n","\n","def train_model(model, train_dataloader):\n","  param_optimizer = list(model.named_parameters()) \n","  optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n","  optimizer = Adam(model.parameters(), lr=3e-6)\n","  torch.cuda.empty_cache()   # Clearing Cache space for a fresh Model run\n","\n","  for epoch_num in range(EPOCHS):\n","    model.train()\n","    train_loss = 0\n","    for step_num, batch_data in enumerate(train_dataloader):\n","        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n","        print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')\n","\n","        tmp = torch.eq(labels, torch.zeros_like(labels))\n","        labels_for_loss = torch.cat((labels, tmp), dim=1)\n","        \n","        logits = model(token_ids, masks).logits\n","        \n","        loss_func = nn.CrossEntropyLoss()\n","        batch_loss = loss_func(logits, labels_for_loss)\n","        train_loss += batch_loss.item()\n","        \n","        model.zero_grad()\n","        batch_loss.backward()\n","\n","        clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","        \n","        clear_output(wait=True)\n","        print('Epoch: ', epoch_num + 1)\n","        print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / BATCH_SIZE, train_loss / (step_num + 1)))\n","  return model"],"metadata":{"id":"tkLU74klE2bI","executionInfo":{"status":"ok","timestamp":1650410737149,"user_tz":-180,"elapsed":315,"user":{"displayName":"Yuvi Cohen","userId":"06088571010261123017"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def eval_model(model, test_dataloader, test_y):\n","  model_predicted = []\n","  all_logits = []\n","  with torch.no_grad():\n","      for step_num, batch_data in enumerate(test_dataloader):\n","          token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n","          tmp = torch.eq(labels, torch.zeros_like(labels))\n","          labels_for_loss = torch.cat((labels, tmp), dim=1)\n","\n","          logits = model(token_ids, masks).logits\n","\n","          loss_func = nn.CrossEntropyLoss()\n","          loss = loss_func(logits, labels_for_loss)\n","          numpy_logits = logits.cpu().detach().numpy()\n","          \n","          model_predicted += list(numpy_logits[:, 0] > 0.5)\n","          all_logits += list(numpy_logits[:, 0])\n","\n","          token_ids, masks, labels = tuple(t.to(\"cpu\") for t in batch_data) # PATCH- move back to cpu\n","  print(type(test_y)) \n","  print(type(model_predicted))        \n","  return classification_report(test_y, model_predicted)"],"metadata":{"id":"e7GeFbHWpcNK","executionInfo":{"status":"ok","timestamp":1650416664480,"user_tz":-180,"elapsed":7,"user":{"displayName":"Yuvi Cohen","userId":"06088571010261123017"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# roberta without finetuning\n","roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","train_dataloader, test_dataloader, test_y = process_data(roberta_tokenizer)\n","roberta = RobertaForSequenceClassification.from_pretrained('roberta-base')\n","report = eval_model(roberta, test_dataloader, test_y)\n","print(report)"],"metadata":{"id":"h-x56xmS-pGJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# finetune Roberta\n","roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","train_dataloader, test_dataloader, test_y = process_data(roberta_tokenizer)\n","roberta = RobertaForSequenceClassification.from_pretrained('roberta-base')\n","roberta = roberta.cuda()\n","roberta_w_finetuning = train_model(roberta, train_dataloader)\n","report = eval_model(roberta_w_finetuning, test_dataloader, test_y)\n","print(report)\n","\n","STATE_PATH = '/content/drive/MyDrive/NLP-Final/roberta_state_w_finetuning'\n","roberta_st = roberta_w_finetuning.state_dict()\n","torch.save(roberta_st, STATE_PATH)"],"metadata":{"id":"SvBRIb0nFSKA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# this is how to load the model\n","roberta_check = RobertaForSequenceClassification.from_pretrained('roberta-base')\n","roberta_check = roberta_check.cuda()\n","roberta_check.load_state_dict(torch.load(STATE_PATH))\n","eval_model(roberta_check, test_dataloader, test_y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":88},"id":"69L2EdDKdz_-","executionInfo":{"status":"ok","timestamp":1650416753956,"user_tz":-180,"elapsed":45168,"user":{"displayName":"Yuvi Cohen","userId":"06088571010261123017"}},"outputId":"ef881ee0-ce87-4e99-accd-98842b4cb18b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.ndarray'>\n","<class 'list'>\n"]},{"output_type":"execute_result","data":{"text/plain":["'              precision    recall  f1-score   support\\n\\n       False       0.93      0.92      0.93       246\\n        True       0.92      0.94      0.93       254\\n\\n    accuracy                           0.93       500\\n   macro avg       0.93      0.93      0.93       500\\nweighted avg       0.93      0.93      0.93       500\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["def print_layers_params(model):\n","  for name,x in model.named_parameters():\n","    if \"intermediate.dense.weight\" in name: # intermidiate is the feed forward part of the layer \n","      print(name)"],"metadata":{"id":"oeLr36FXZEAU"},"execution_count":null,"outputs":[]}]}